% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}

\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\usepackage{hyperref}
\hypersetup{
     colorlinks   = true,
     citecolor    = cyan
}
\usepackage{bbm}
\usepackage{dsfont}

\begin{document}

\title{Handwritten Digits Classification
% \titlenote{(Does NOT produce the permission block, copyright information nor page numbering). For use with ACM\_PROC\_ARTICLE-SP.CLS. Supported by ACM.}
}
\subtitle{[Team Y.E.S.: COMP 598 Group Project 3]
\titlenote{
The dataset and the implementation of the algorithm described in this report is available at
\url{https://github.com/yutingyw/imageClassification}}}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Yuting Wen \\
 \affaddr{McGill University}\\
      % \affaddr{P.O. Box 1212}\\
      % \affaddr{Dublin, Ohio 43017-6221}\\
       \email{yuting.wen@mail.mcgill.ca}     
% 2nd. author
\alignauthor
Emmanuel Bengio\\
  \affaddr{McGill University}\\
       %\affaddr{1932 Wallamaloo Lane}\\
      % \affaddr{Wallamaloo, New Zealand}\\
       \email{emmanuel.bengio@mail.mcgill.ca}        
% 3rd. author
\alignauthor Sherry Shanshan Ruan\\
       \affaddr{McGill University}\\
      % \affaddr{1 Th{\o}rv{\"a}ld Circle}\\
     %  \affaddr{Hekla, Iceland}\\
     \email{shanshan.ruan@mail.mcgill.ca}
%\and  % use '\and' if you need 'another row' of author names
%% 4th. author
%\alignauthor Lawrence P. Leipuner\\
%       \affaddr{Brookhaven Laboratories}\\
%       \affaddr{Brookhaven National Lab}\\
%       \affaddr{P.O. Box 5000}\\
%       \email{lleipuner@researchlabs.org}
%% 5th. author
%\alignauthor Sean Fogarty\\
%       \affaddr{NASA Ames Research Center}\\
%       \affaddr{Moffett Field}\\
%       \affaddr{California 94035}\\
%       \email{fogartys@amesres.org}
%% 6th. author
%\alignauthor Charles Palmer\\
%       \affaddr{Palmer Research Laboratories}\\
%       \affaddr{8600 Datapoint Drive}\\
%       \affaddr{San Antonio, Texas 78229}\\
%       \email{cpalmer@prl.com}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
%email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
%(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
In this project, we aim at classify a much more difficult variation of the MNIST dataset of handwritten digits. We adopt feature selection and construction techniques together with four main machine learning algorithms: Gaussian Naive Bayes, fully connected Feedforward Neural Network, Linear Support Vector Machine, and XXX (name of the 4th algorithm here). We analyze and assess the parameter selection process and the performance of each algorithm. We conclude the report with discussion and suggestions for further improvement.
\end{abstract}

%% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]
%
%\terms{Theory}
%
%\keywords{ACM proceedings, \LaTeX, text tagging} % NOT required for Proceedings


%-------------------------------------- Introduction  --------------------------------------%
\section{Introduction}
The MNIST database of handwritten digits \cite{mnistlecun} is a standard touchstone of effective image classification algorithms.  It is  extensively studied and tested by many machine learning techniques \cite{726791, Jou:2004:HNR:1123321.1123360, Huang:2009:SFD:1704175.1704194, mnistTheano} . The original dataset consists of more than 60,000 handwritten digits from 0 to 9, normalized to a 28x28 fixed image size \cite{mnistlecun}. 

The dataset we are dealing with in this project is more challenging. Modifications of the original dataset include embossing, rotation, rescaling, and texture pattern. These artificial alterations introduce a great amount of noise and undoubtedly increase the  level of difficulty of the digit classification task. The modified dataset contains 50,000 training examples of 48x48 fixed size, and the test set comprises 20,000 instances which require classification.

We decided to apply four different algorithms: Naive Bayes, Feedforward Neural Networks, Linear Support Vector Machine, and XXX to the modified MNIST dataset. In Naive Bayes, we adopt some basic data proprecessing techniques such as normalization to  better adapt to the algorithm. We chose Gaussian Naive Bayes since features given as float numbers are continuous.  For Neural Networks, ..... For Linear SVM, ..... For XXX, ..... (one or two sentences summarizing each algorithm)

The performance of algorithms varies widely. The base line algorithm, Naive Bayes, provides around 40$\%$ accuracy, this may due to the fact that the Naive Bayes assumption does not hold in the digit classification task in general. NN..... . SVM..... XXX..... (one or two sentences summarizing the performance)

Our empirical results, though preliminary, provide considerably accurate predictions (especially XXX) for the modified MNIST digit classification. Thus, we are optimistic of applying the algorithms and analysis presented in this report to other real-world  classification problems. This may motivate the further study on more specialized machine learning algorithms on image classification tasks.

%-------------------------------------- Related work --------------------------------------%
\section{Related Work}
Optional








%-------------------------------------- Data Preprocessing --------------------------------------%
\section{Data Preprocessing}
data preprocessing methods










%-------------------------------------- Feature Design and Selection --------------------------------------%
\section{Feature Design and Selection}
feature design and selection methods


%-------------------------------------- Algorithm Selection --------------------------------------%
\section{Algorithm Selection}

\subsection{Baseline: }

\subsection{Neural Net}

\subsection{Open: }
algorithm selection for each of the 3 categories (baseline, neural net, open)

%-------------------------------------- Optimization --------------------------------------%
\section{Optimization}

\subsection{Baseline: }

\subsection{Neural Net}

\subsection{Open: }
optimization methods  for each of the 3 categories (baseline, neural net, open)


%-------------------------------------- Parameter Selection --------------------------------------%
\section{Parameter Selection}



\subsection{Baseline: }

\subsection{Neural Net}

\subsection{Open: }
model	order,	learning	rate,	etc.  for each of the 3 categories (baseline, neural net, open)

%-------------------------------------- Testing and Validation --------------------------------------%
\section{Testing and Validation}


\subsection{Baseline: }

\subsection{Neural Net}

\subsection{Open: }
detailed	analysis of	your	results,	outside	of	Kaggle  for each of the 3 categories (baseline, neural net, open)



\section{Discussion}
pros and cons	of	your	approach and	methodology)


We	hereby	state	that	all	the	work	 presented	in	this	report	is	that	of	the	authors
\bibliographystyle{abbrv}
\bibliography{sigproc}  

\end{document}
